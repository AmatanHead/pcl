package com.github.amatanhead.pcl.stream;

import com.github.amatanhead.pcl.errors.LexerProtocolError;
import com.github.amatanhead.pcl.errors.NoBacktrackingTokenError;
import com.github.amatanhead.pcl.errors.NoNewTokenError;
import com.github.amatanhead.pcl.errors.TokenizationError;
import com.github.amatanhead.pcl.token.Token;

import java.util.Iterator;
import java.util.ListIterator;
import java.util.Stack;


/**
 * A wrapper for converting {@link Iterator<Token>} into a {@link TokenStream}.
 */
final class DefaultIteratorStream extends StandardUnclearable implements TokenStream {
    private final Iterator<Token> iterator;

    DefaultIteratorStream(Iterator<Token> iterator) {
        this.iterator = iterator;
    }

    @Override
    public Token input() {
        markUnclear();

        if (canInput()) {
            return iterator.next();
        } else {
            throw new NoNewTokenError("no tokens left in the stream");
        }
    }

    @Override
    public boolean canInput() {
        return iterator.hasNext();
    }
}


/**
 * A wrapper for converting {@link ListIterator<Token>} into a {@link TokenStreamStar}.
 */
final class DefaultListIteratorStream extends StandardUnclearableBookmarkable implements TokenStreamStar {
    private final ListIterator<Token> iterator;

    DefaultListIteratorStream(ListIterator<Token> iterator) {
        this.iterator = iterator;
    }

    @Override
    public Token unput() {
        if (canUnput()) {
            onUnput();
            return iterator.previous();
        } else {
            throw new NoBacktrackingTokenError("no tokens left in the backtracking stack");
        }
    }

    @Override
    public boolean canUnput() {
        return iterator.hasPrevious();
    }

    @Override
    public Token input() {
        markUnclear();

        if (canInput()) {
            onInput();
            return iterator.next();
        } else {
            throw new NoNewTokenError("no tokens left in the stream");
        }
    }

    @Override
    public boolean canInput() {
        return iterator.hasNext();
    }

    @Override
    public boolean isClear() {
        return iterator.nextIndex() == 0;
    }
}


/**
 * A wrapper which ads {@link TokenStream1} functionality to existing base token stream.
 * <p>
 * This wrapper keeps last token that was generated by the underlying stream, handling all unput procedures
 * and delegating input procedures to the underlying stream.
 */
final class DefaultStream1 extends StandardUnclearable implements TokenStream1 {
    private final TokenStream tokenStream;

    Token prev = null;
    Token next = null;

    DefaultStream1(TokenStream tokenStream) {
        this.tokenStream = tokenStream;
    }

    @Override
    public Token unput() {
        if (prev == null) {
            throw new NoBacktrackingTokenError("no previous token available");
        }

        next = prev;
        prev = null;

        return next;
    }

    @Override
    public boolean canUnput() {
        return prev != null;
    }

    @Override
    public Token input() throws TokenizationError {
        markUnclear();

        Token token;

        if (next != null) {
            token = next;
        } else {
            token = tokenStream.input();
        }

        next = null;
        prev = token;

        return token;
    }

    @Override
    public boolean canInput() {
        return (next != null) || tokenStream.canInput();
    }
}


/**
 * A wrapper which ads {@link TokenStreamN} functionality to existing base token stream.
 * <p>
 * This wrapper keeps a backtracking stack, handling all unput procedures and delegating input
 * procedures to the underlying stream.
 */
final class DefaultStreamN extends StandardUnclearable implements TokenStreamN {
    private final TokenStream tokenStream;

    private final Stack<Token> backtrackingStack = new Stack<>();

    DefaultStreamN(TokenStream tokenStream) {
        this.tokenStream = tokenStream;
    }

    @Override
    public Token unput(Token token) {
        backtrackingStack.push(token);
        return token;
    }

    @Override
    public Token input() throws TokenizationError {
        markUnclear();

        if (!backtrackingStack.empty()) {
            return backtrackingStack.pop();
        } else {
            return tokenStream.input();
        }
    }

    @Override
    public boolean canInput() {
        return !backtrackingStack.empty() || tokenStream.canInput();
    }
}


/**
 * A wrapper which ads {@link TokenStreamStar} functionality to existing base token stream.
 * <p>
 * This wrapper keeps a list of all tokens that was generated by the underlying stream and a backtracking stack,
 * handling all unput procedures and delegating input procedures to the underlying stream.
 */
final class DefaultStreamStar extends StandardUnclearableBookmarkable implements TokenStreamStar {
    private final TokenStream tokenStream;

    private final Stack<Token> backtrackingStack = new Stack<>();
    private final Stack<Token> savedStack = new Stack<>();

    DefaultStreamStar(TokenStream tokenStream) {
        this.tokenStream = tokenStream;
    }

    @Override
    public Token unput() {
        if (canUnput()) {
            onUnput();
            Token token = savedStack.pop();
            backtrackingStack.push(token);
            return token;
        } else {
            throw new NoBacktrackingTokenError("no tokens left in the backtracking stack");
        }
    }

    @Override
    public boolean canUnput() {
        return !savedStack.empty();
    }

    @Override
    public Token input() throws TokenizationError {
        markUnclear();

        Token token;

        if (!backtrackingStack.empty()) {
            onInput();
            token = backtrackingStack.pop();
        } else if (canInput()) {
            onInput();
            token = tokenStream.input();
        } else {
            throw new NoNewTokenError("no tokens left in the stream");
        }

        savedStack.push(token);

        return token;
    }

    @Override
    public boolean canInput() {
        return !backtrackingStack.empty() || tokenStream.canInput();
    }
}


/**
 * Commonly used conversions between token stream types. Allow adding new features to basic token stream.
 * For example, one can turn the default {@link TokenStream} into a full-featured {@link TokenStreamN}.
 */
public final class StandardConversions {
    /**
     * Protect constructor since this is a static-only class.
     */
    protected StandardConversions() {
    }

    /**
     * Convert arbitrary token stream into a non-backtrackable token stream.
     *
     * @throws LexerProtocolError no conversion can be applied to an unclear token stream. See {@link TokenStream#isClear()}.
     */
    static public TokenStream toStream(TokenStream tokenStream) {
        if (!tokenStream.isClear()) {
            throw new LexerProtocolError("no conversion can be applied to an unclear token stream");
        }

        return tokenStream;
    }

    /**
     * Convert an iterator into a proper token stream.
     */
    static public TokenStream toStream(Iterator<Token> iterator) {
        if (iterator instanceof ListIterator) {
            return new DefaultListIteratorStream((ListIterator<Token>) iterator);
        } else {
            return new DefaultIteratorStream(iterator);
        }
    }

    /**
     * Convert arbitrary token stream into a one-backtrackable token stream.
     * <p>
     * If given `tokenStream` is an a one-backtrackable stream, this function is noop.
     * <p>
     * Otherwise, it returns a default wrapper which delegates `input()` and `canInput()` to the original
     * stream and adds support for `unput()`.
     *
     * @throws LexerProtocolError no conversion can be applied to an unclear token stream. See {@link TokenStream#isClear()}.
     */
    static public TokenStream1 toStream1(TokenStream tokenStream) {
        if (!tokenStream.isClear()) {
            throw new LexerProtocolError("no conversion can be applied to an unclear token stream");
        }

        if (tokenStream instanceof TokenStream1) {
            return (TokenStream1) tokenStream;
        } else {
            return new DefaultStream1(tokenStream);
        }
    }

    /**
     * Convert arbitrary token stream into an N-backtrackable token stream.
     * <p>
     * If given `tokenStream` is an an N-backtrackable stream, this function is noop.
     * <p>
     * Otherwise, it returns a default wrapper which delegates `input()` and `canInput()` to the original
     * stream and adds support for `unput()`.
     *
     * @throws LexerProtocolError no conversion can be applied to an unclear token stream. See {@link TokenStream#isClear()}.
     */
    static public TokenStreamN toStreamN(TokenStream tokenStream) {
        if (!tokenStream.isClear()) {
            throw new LexerProtocolError("no conversion can be applied to an unclear token stream");
        }

        if (tokenStream instanceof TokenStreamN) {
            return (TokenStreamN) tokenStream;
        } else {
            return new DefaultStreamN(tokenStream);
        }
    }

    /**
     * Convert arbitrary token stream into a *-backtrackable token stream.
     * <p>
     * If given `tokenStream` is an a *-backtrackable stream, this function is noop.
     * <p>
     * Otherwise, it returns a default wrapper which delegates `input()` and `canInput()` to the original
     * stream and adds support for `unput()`.
     *
     * @throws LexerProtocolError no conversion can be applied to an unclear token stream. See {@link TokenStream#isClear()}.
     */
    static public TokenStreamStar toStreamStar(TokenStream tokenStream) {
        if (!tokenStream.isClear()) {
            throw new LexerProtocolError("no conversion can be applied to an unclear token stream");
        }

        if (tokenStream instanceof TokenStreamStar) {
            return (TokenStreamStar) tokenStream;
        } else {
            return new DefaultStreamStar(tokenStream);
        }
    }
}
